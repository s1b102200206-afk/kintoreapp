import streamlit as st
import cv2
import tempfile
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import os

st.set_page_config(page_title="ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆå§¿å‹¢è§£æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ‹ï¸â€â™‚ï¸ ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆå§¿å‹¢è§£æã‚¢ãƒ—ãƒª")
st.write("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è†ã®è§’åº¦ã‚’è§£æã—ã€æµ…ã‚ãƒ»æ·±ã‚ã®æ³¨æ„ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_model():
    model = hub.load("https://tfhub.dev/google/movenet/singlepose/thunder/4")
    movenet = model.signatures['serving_default']  # â† ã“ã“ãŒé‡è¦
    return movenet

movenet = load_model()

# --- å§¿å‹¢æ¨å®š ---
def detect_keypoints(frame):
    input_image = tf.image.resize_with_pad(tf.expand_dims(frame, axis=0), 256, 256)
    input_image = tf.cast(input_image, dtype=tf.int32)
    outputs = movenet(input_image)
    keypoints = outputs['output_0'].numpy()[0,0,:,:]  # 17 keypoints
    return keypoints

# --- è†è§’åº¦è¨ˆç®— ---
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0:
        angle = 360 - angle
    return angle

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["mp4","mov","avi"])
mode = st.radio("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ("æµ…ã‚ãƒ¢ãƒ¼ãƒ‰", "æ·±ã‚ãƒ¢ãƒ¼ãƒ‰"))

if uploaded_file is not None:
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile.write(uploaded_file.read())
    tfile.close()

    cap = cv2.VideoCapture(tfile.name)
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # å‡ºåŠ›å‹•ç”»ç”¨
    out_path = os.path.join(tempfile.gettempdir(), "squat_result.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

    stframe = st.empty()
    st.write("ğŸ” è§£æä¸­ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„â€¦")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        keypoints = detect_keypoints(img_rgb)

        # å·¦è†ã®åº§æ¨™å–å¾—
        left_hip = keypoints[11][:2] * [width, height]
        left_knee = keypoints[13][:2] * [width, height]
        left_ankle = keypoints[15][:2] * [width, height]

        angle = calculate_angle(left_hip, left_knee, left_ankle)

        # åˆ¤å®š
        if mode == "æµ…ã‚ãƒ¢ãƒ¼ãƒ‰":
            if angle <= 90:
                text = f"æ·±ã‚æ³¨æ„ï¼ {int(angle)}Â°"
                color = (0,0,255)
            else:
                text = f"è§’åº¦: {int(angle)}Â°"
                color = (0,255,0)
        else:  # æ·±ã‚ãƒ¢ãƒ¼ãƒ‰
            if angle > 90:
                text = f"æµ…ã‚æ³¨æ„ï¼ {int(angle)}Â°"
                color = (0,0,255)
            else:
                text = f"è§’åº¦: {int(angle)}Â°"
                color = (0,255,0)

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ–‡å­—æç”»
        cv2.putText(frame, text, (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
        out.write(frame)

        # é€²æ—è¡¨ç¤ºï¼ˆé™æ­¢ç”»ã§ç¢ºèªç”¨ï¼‰
        stframe.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB")

    cap.release()
    out.release()

    st.success("âœ… è§£æå®Œäº†ï¼")

    # çµæœå‹•ç”»ã‚’å†ç”Ÿã¯ã›ãšã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã¿
    with open(out_path, "rb") as f:
        st.download_button("ğŸ“¥ è§£æå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=f, file_name="squat_result.mp4", mime="video/mp4")
