import streamlit as st
import cv2
import tempfile
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import os

st.title("ğŸ‹ï¸ ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆå§¿å‹¢è§£æã‚¢ãƒ—ãƒªï¼ˆè»½é‡ç‰ˆï¼‰")
st.write("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è†è§’åº¦ã‚’è§£æã—ã€æµ…ã‚ãƒ»æ·±ã‚ãƒ¢ãƒ¼ãƒ‰ã§è­¦å‘Šè¡¨ç¤ºã—ã¾ã™ã€‚")

# ãƒ¢ãƒ¼ãƒ‰é¸æŠ
mode = st.radio("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ("æµ…ã‚ãƒ¢ãƒ¼ãƒ‰", "æ·±ã‚ãƒ¢ãƒ¼ãƒ‰"))

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
@st.cache_resource
def load_model():
    model = hub.load("https://tfhub.dev/google/movenet/singlepose/thunder/4")
    return model

movenet = load_model()

# å§¿å‹¢æ¨å®š
def detect_keypoints(frame):
    input_image = tf.image.resize_with_pad(tf.expand_dims(frame, axis=0), 256, 256)
    input_image = tf.cast(input_image, dtype=tf.int32)
    outputs = movenet(input_image)
    keypoints = outputs['output_0'].numpy()[0,0,:,:]  # 17 keypoints
    return keypoints

# è†è§’åº¦è¨ˆç®—
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0:
        angle = 360 - angle
    return angle

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["mp4","mov","avi"])

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile.write(uploaded_file.read())
    tfile.close()

    cap = cv2.VideoCapture(tfile.name)
    fps = cap.get(cv2.CAP_PROP_FPS)
    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # è»½é‡åŒ–ç”¨ã‚µã‚¤ã‚º
    new_width = 320
    new_height = int(orig_height * new_width / orig_width)

    out_path = os.path.join(tempfile.gettempdir(), "squat_result.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(out_path, fourcc, fps, (new_width, new_height))

    stframe = st.empty()
    st.write("ğŸ” è§£æä¸­ã§ã™ã€‚å°‘ã—ãŠå¾…ã¡ãã ã•ã„â€¦")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # ãƒªã‚µã‚¤ã‚º
        frame = cv2.resize(frame, (new_width, new_height))
        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        keypoints = detect_keypoints(img_rgb)

        left_hip = keypoints[11][:2] * [new_width, new_height]
        left_knee = keypoints[13][:2] * [new_width, new_height]
        left_ankle = keypoints[15][:2] * [new_width, new_height]

        angle = calculate_angle(left_hip, left_knee, left_ankle)

        # ãƒ¢ãƒ¼ãƒ‰åˆ¤å®š
        if mode == "æµ…ã‚ãƒ¢ãƒ¼ãƒ‰":
            text = f"æ·±ã‚æ³¨æ„ï¼ {int(angle)}Â°" if angle <= 90 else f"è§’åº¦: {int(angle)}Â°"
            color = (0,0,255) if angle <= 90 else (0,255,0)
        else:
            text = f"æµ…ã‚æ³¨æ„ï¼ {int(angle)}Â°" if angle >= 100 else f"è§’åº¦: {int(angle)}Â°"
            color = (0,0,255) if angle >= 100 else (0,255,0)

        cv2.putText(frame, text, (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        out.write(frame)
        stframe.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB")

    cap.release()
    out.release()

    st.success("âœ… è§£æå®Œäº†ï¼")

    # å‹•ç”»å†ç”Ÿï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    with open(out_path, "rb") as f:
        video_bytes = f.read()
        st.video(video_bytes)
        st.download_button("ğŸ“¥ è§£æå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=video_bytes, file_name="squat_result.mp4", mime="video/mp4")
